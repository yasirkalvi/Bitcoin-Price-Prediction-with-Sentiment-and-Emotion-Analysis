{"cells":[{"cell_type":"code","execution_count":null,"id":"69d1dd4e","metadata":{"id":"69d1dd4e"},"outputs":[],"source":["!pip install tweepy\n","import tweepy\n","import tweepy\n","import time\n","from textblob import TextBlob\n","\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","plt.style.use(\"fivethirtyeight\")\n","\n","import nltk\n","nltk.download('all')\n","\n","!pip install NRCLex\n","from nrclex import NRCLex"]},{"cell_type":"code","execution_count":null,"id":"3637623c","metadata":{"id":"3637623c"},"outputs":[],"source":["consumerKey = \"6bDyiwANMUAyfThjAPLXMEmbI\"\n","consumerSecret = \"cPVwuqxv8JnN4L41IwWgcRYaLhEeGub8mYGzlTJzw1lTDDNeYO\"\n","bearer_token = \"AAAAAAAAAAAAAAAAAAAAAFc0ggEAAAAAJUlQ2Itfjttg2%2BsynZ4CWNMVU9s%3DceUCxm1EHpsNws84B77DAMrNpgJfbVVxg6MWOh5VLmRbPbm3Ko\"\n","\n","accessToken = \"1564594719904120836-ZSdYGzkk1xZp36hIDHpIGQYaCFcKnj\"\n","accessTokenSecret = \"9fzywTS4zI91SASBSn3sHjC43Piu0JB0hqjXCIBsbOlbk\"\n"]},{"cell_type":"code","execution_count":null,"id":"ffdeca4b","metadata":{"id":"ffdeca4b"},"outputs":[],"source":["#Create the authentication object\n","\n","auth = tweepy.OAuthHandler(\n","   consumerKey, consumerSecret\n",")\n","auth.set_access_token(accessToken, accessTokenSecret)\n","auth.secure = True\n","\n","api = tweepy.API(auth, wait_on_rate_limit = True)\n","\n","\n","client = tweepy.Client(bearer_token = bearer_token)\n"]},{"cell_type":"code","execution_count":null,"id":"242e47d5","metadata":{"id":"242e47d5"},"outputs":[],"source":["##Tweets count\n","\n","\n","client = tweepy.Client(bearer_token = bearer_token)\n","\n","query = 'BTC OR $BTC -is:retweet'\n","\n","counts = client.get_all_tweets_count(query=query, start_time='2021-11-04T00:00:00Z', end_time='2022-06-20T00:00:00Z', granularity = 'day')\n","\n","r=0\n","\n","l=0\n","\n","for count in counts.data:\n","    r=r+count['tweet_count']\n","    l=l+1\n","    #print(count)\n","\n","print(r)\n","print(l)\n","\n","\n","##Tweets count with Paginator\n","\n","\n","\n","r=0\n","l=0\n","for tweet in tweepy.Paginator(client.get_all_tweets_count, \"(Bitcoin) -rt -retweet -winner -giveaway -follow -is:retweet lang:en -has:media -has:images -has:videos -is:reply -has:links\", granularity = 'day', start_time='2022-02-01T00:00:00Z', end_time='2022-04-05T00:00:00Z').flatten():\n","    r=r+tweet['tweet_count']\n","    l=l+1\n","    #print(tweet['tweet_count'])\n","    #print(tweet)\n","\n","\n","print(r)\n","print(l)"]},{"cell_type":"code","execution_count":null,"id":"2b448d9f","metadata":{"id":"2b448d9f"},"outputs":[],"source":["##All tweets API Paginator\n","\n","\n","query = \"(Bitcoin) -rt -retweet -winner -giveaway -follow -is:retweet lang:en -has:media -has:images -has:videos -is:reply -has:links\"\n","\n","tweets = tweepy.Paginator(client.search_all_tweets,\n","                          query=query,\n","                          user_fields = ['username', 'public_metrics', 'description', 'location'],\n","                          expansions = 'author_id',\n","                          start_time='2022-02-01T00:00:00Z', end_time='2022-04-05T00:00:00Z',\n","                          max_results = 500,\n","                          tweet_fields=['created_at', 'geo', 'public_metrics', 'text'])\n","btc_tweets=[]\n","\n","for response in tweets:\n","    time.sleep(1)\n","    btc_tweets.append(response)\n","\n","print(btc_tweets)\n","\n","\n","result = []\n","user_dict = {}\n","# Loop through each response object\n","for response in btc_tweets:\n","    # Taking all of the users, and putting them into a dictionary of dictionaries with the info we want to keep\n","    for user in response.includes['users']:\n","        user_dict[user.id] = {'username': user.username,\n","                              'followers': user.public_metrics['followers_count'],\n","                              'tweets': user.public_metrics['tweet_count'],\n","                              'location': user.location\n","                             }\n","    for tweet in response.data:\n","        # For each tweet, we will find the author's information\n","        author_info = user_dict[tweet.author_id]\n","        # Putting all of the information we want to keep in a single dictionary for each tweet\n","        result.append({'author_id': tweet.author_id,\n","                       'username': author_info['username'],\n","                       'author_followers': author_info['followers'],\n","                       'author_tweets': author_info['tweets'],\n","                       'author_location': author_info['location'],\n","                       'text': tweet.text,\n","                       'created_at': tweet.created_at,\n","                       'retweets': tweet.public_metrics['retweet_count'],\n","                       'replies': tweet.public_metrics['reply_count'],\n","                       'likes': tweet.public_metrics['like_count'],\n","                       'quote_count': tweet.public_metrics['quote_count']\n","                      })\n","\n","# Changing this list of dictionaries into a dataframe\n","df = pd.DataFrame(result)\n","\n","\n","\n","\n","\n","print(df)\n","\n","\n","\n","\n","\n","#df to df to csv python\n","\n","df.to_csv('tweet.csv')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[{"file_id":"1sUWJZC_DnTwBx6YQWc_Xt6PHxiU4PIh8","timestamp":1663662330654}],"machine_shape":"hm","collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}